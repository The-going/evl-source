From 1394192cd8aa894f9ed6868ec501a287cb41af6a Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Thu, 10 Jan 2019 17:16:42 +0100
Subject: [PATCH] kernel/panic: irq_pipeline: enable panic handling from oob
 context

---
 kernel/panic.c | 27 +++++++++++++++++----------
 1 file changed, 17 insertions(+), 10 deletions(-)

diff --git a/kernel/panic.c b/kernel/panic.c
index 47e8ebccc22b..62c064e20263 100644
--- a/kernel/panic.c
+++ b/kernel/panic.c
@@ -27,6 +27,7 @@
 #include <linux/sysrq.h>
 #include <linux/init.h>
 #include <linux/nmi.h>
+#include <linux/irq_pipeline.h>
 #include <linux/console.h>
 #include <linux/bug.h>
 #include <linux/ratelimit.h>
@@ -41,7 +42,7 @@ static unsigned long tainted_mask =
 	IS_ENABLED(CONFIG_GCC_PLUGIN_RANDSTRUCT) ? (1 << TAINT_RANDSTRUCT) : 0;
 static int pause_on_oops;
 static int pause_on_oops_flag;
-static DEFINE_SPINLOCK(pause_on_oops_lock);
+static DEFINE_HARD_SPINLOCK(pause_on_oops_lock);
 bool crash_kexec_post_notifiers;
 int panic_on_warn __read_mostly;
 
@@ -179,7 +180,9 @@ void panic(const char *fmt, ...)
 	 * there is nothing to prevent an interrupt handler (that runs
 	 * after setting panic_cpu) from invoking panic() again.
 	 */
-	local_irq_disable();
+	hard_local_irq_disable();
+
+	irq_pipeline_oops();
 
 	/*
 	 * It's possible to come here directly from a panic-assertion and
@@ -256,9 +259,12 @@ void panic(const char *fmt, ...)
 
 	/*
 	 * Run any panic handlers, including those that might need to
-	 * add information to the kmsg dump output.
+	 * add information to the kmsg dump output. Skip panic
+	 * handlers if running over the oob stage, as they would most
+	 * likely break.
 	 */
-	atomic_notifier_call_chain(&panic_notifier_list, 0, buf);
+	if (running_inband())
+		atomic_notifier_call_chain(&panic_notifier_list, 0, buf);
 
 	/* Call flush even twice. It tries harder with a single online CPU */
 	printk_safe_flush_on_panic();
@@ -458,7 +464,7 @@ static void do_oops_enter_exit(void)
 	if (!pause_on_oops)
 		return;
 
-	spin_lock_irqsave(&pause_on_oops_lock, flags);
+	raw_spin_lock_irqsave(&pause_on_oops_lock, flags);
 	if (pause_on_oops_flag == 0) {
 		/* This CPU may now print the oops message */
 		pause_on_oops_flag = 1;
@@ -468,21 +474,21 @@ static void do_oops_enter_exit(void)
 			/* This CPU gets to do the counting */
 			spin_counter = pause_on_oops;
 			do {
-				spin_unlock(&pause_on_oops_lock);
+				raw_spin_unlock(&pause_on_oops_lock);
 				spin_msec(MSEC_PER_SEC);
-				spin_lock(&pause_on_oops_lock);
+				raw_spin_lock(&pause_on_oops_lock);
 			} while (--spin_counter);
 			pause_on_oops_flag = 0;
 		} else {
 			/* This CPU waits for a different one */
 			while (spin_counter) {
-				spin_unlock(&pause_on_oops_lock);
+				raw_spin_unlock(&pause_on_oops_lock);
 				spin_msec(1);
-				spin_lock(&pause_on_oops_lock);
+				raw_spin_lock(&pause_on_oops_lock);
 			}
 		}
 	}
-	spin_unlock_irqrestore(&pause_on_oops_lock, flags);
+	raw_spin_unlock_irqrestore(&pause_on_oops_lock, flags);
 }
 
 /*
@@ -512,6 +518,7 @@ void oops_enter(void)
 {
 	tracing_off();
 	/* can't trust the integrity of the kernel anymore: */
+	irq_pipeline_oops();
 	debug_locks_off();
 	do_oops_enter_exit();
 }
-- 
2.16.4

