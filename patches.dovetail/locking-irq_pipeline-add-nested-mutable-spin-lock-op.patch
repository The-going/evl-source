From 7c44ffd4ae2461fa4ab8e2055d7c219b815175f3 Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Sat, 2 Nov 2019 10:43:45 +0100
Subject: [PATCH] locking: irq_pipeline: add nested mutable spin lock operation

Signed-off-by: Philippe Gerum <rpm@xenomai.org>
---
 include/linux/spinlock_pipeline.h | 33 ++++++++++++++++++++++++---------
 kernel/locking/pipeline.c         | 27 +++++++++++++++++++++------
 2 files changed, 45 insertions(+), 15 deletions(-)

diff --git a/include/linux/spinlock_pipeline.h b/include/linux/spinlock_pipeline.h
index f5c15da33b81..49d84202338a 100644
--- a/include/linux/spinlock_pipeline.h
+++ b/include/linux/spinlock_pipeline.h
@@ -221,6 +221,7 @@ int hard_spin_is_contended(struct raw_spinlock *rlock)
  */
 
 void __mutable_spin_lock(struct raw_spinlock *rlock);
+void __mutable_spin_lock_nested(struct raw_spinlock *rlock, int subclass);
 
 static inline void mutable_spin_lock(struct raw_spinlock *rlock)
 {
@@ -230,14 +231,30 @@ static inline void mutable_spin_lock(struct raw_spinlock *rlock)
 		__mutable_spin_lock(rlock);
 }
 
+#ifdef CONFIG_DEBUG_LOCK_ALLOC
+static inline
+void mutable_spin_lock_nested(struct raw_spinlock *rlock, int subclass)
+{
+	if (in_pipeline())
+		hard_lock_acquire_nested(rlock, subclass, _THIS_IP_);
+	else
+		__mutable_spin_lock_nested(rlock, subclass);
+}
+#else
+static inline
+void mutable_spin_lock_nested(struct raw_spinlock *rlock, int subclass)
+{
+	mutable_spin_lock(rlock);
+}
+#endif
+
 void __mutable_spin_unlock(struct raw_spinlock *rlock);
 
 static inline void mutable_spin_unlock(struct raw_spinlock *rlock)
 {
-	if (in_pipeline()) {
+	if (in_pipeline())
 		hard_lock_release(rlock, _THIS_IP_);
-		do_raw_spin_unlock(rlock);
-	} else
+	else
 		__mutable_spin_unlock(rlock);
 }
 
@@ -255,10 +272,9 @@ void __mutable_spin_unlock_irq(struct raw_spinlock *rlock);
 
 static inline void mutable_spin_unlock_irq(struct raw_spinlock *rlock)
 {
-	if (in_pipeline()) {
+	if (in_pipeline())
 		hard_lock_release(rlock, _THIS_IP_);
-		do_raw_spin_unlock(rlock);
-	} else
+	else
 		__mutable_spin_unlock_irq(rlock);
 }
 
@@ -280,10 +296,9 @@ static inline void mutable_spin_unlock_irqrestore(struct raw_spinlock *rlock,
 						  unsigned long flags)
 {
 
-	if (in_pipeline()) {
+	if (in_pipeline())
 		hard_lock_release(rlock, _THIS_IP_);
-		do_raw_spin_unlock(rlock);
-	} else
+	else
 		__mutable_spin_unlock_irqrestore(rlock, flags);
 }
 
diff --git a/kernel/locking/pipeline.c b/kernel/locking/pipeline.c
index ba16dafe502f..61190ab5e0e4 100644
--- a/kernel/locking/pipeline.c
+++ b/kernel/locking/pipeline.c
@@ -43,15 +43,30 @@ void __mutable_spin_lock(struct raw_spinlock *rlock)
 }
 EXPORT_SYMBOL(__mutable_spin_lock);
 
+void __mutable_spin_lock_nested(struct raw_spinlock *rlock, int subclass)
+{
+	struct mutable_spinlock *lock;
+	unsigned long __flags;
+
+	if (running_inband())
+		preempt_disable();
+
+	__flags = hard_local_irq_save();
+	hard_lock_acquire_nested(rlock, subclass, _RET_IP_);
+	lock = container_of(rlock, struct mutable_spinlock, rlock);
+	lock->hwflags = __flags;
+}
+EXPORT_SYMBOL(__mutable_spin_lock_nested);
+
 void __mutable_spin_unlock(struct raw_spinlock *rlock)
 {
 	struct mutable_spinlock *lock;
 	unsigned long __flags;
 
-	hard_lock_release(rlock, _RET_IP_);
+	/* Pick the flags before releasing the lock. */
 	lock = container_of(rlock, struct mutable_spinlock, rlock);
 	__flags = lock->hwflags;
-	do_raw_spin_unlock(rlock);
+	hard_lock_release(rlock, _RET_IP_);
 	hard_local_irq_restore(__flags);
 
 	if (running_inband())
@@ -83,10 +98,10 @@ void __mutable_spin_unlock_irq(struct raw_spinlock *rlock)
 	struct mutable_spinlock *lock;
 	unsigned long __flags;
 
-	hard_lock_release(rlock, _RET_IP_);
+	/* Pick the flags before releasing the lock. */
 	lock = container_of(rlock, struct mutable_spinlock, rlock);
 	__flags = lock->hwflags;
-	do_raw_spin_unlock(rlock);
+	hard_lock_release(rlock, _RET_IP_);
 
 	if (running_inband()) {
 		trace_hardirqs_on();
@@ -128,10 +143,10 @@ void __mutable_spin_unlock_irqrestore(struct raw_spinlock *rlock,
 	struct mutable_spinlock *lock;
 	unsigned long __flags;
 
-	hard_lock_release(rlock, _RET_IP_);
+	/* Pick the flags before releasing the lock. */
 	lock = container_of(rlock, struct mutable_spinlock, rlock);
 	__flags = lock->hwflags;
-	do_raw_spin_unlock(rlock);
+	hard_lock_release(rlock, _RET_IP_);
 
 	if (running_inband()) {
 		if (!flags) {
-- 
2.16.4

