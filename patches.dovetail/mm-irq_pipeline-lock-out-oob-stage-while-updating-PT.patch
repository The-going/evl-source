From df19bf875bbae2007b70b28986235ebf676d1db8 Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Thu, 21 Jul 2016 08:57:40 +0200
Subject: [PATCH] mm: irq_pipeline: lock out oob stage while updating PTE range

In the non-numa case, change_pte_range() will mark each updated PTE in
a range as absent, while the protbits are being fixed up, to make sure
it won't race with the hardware.

We don't want any oob code to preempt the in-band context until the
updated protbits are written back, so we have to hard disable IRQs
around this section.

Signed-off-by: Philippe Gerum <rpm@xenomai.org>
---
 mm/mprotect.c | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/mm/mprotect.c b/mm/mprotect.c
index 7a8e84f86831..78ca356c09c6 100644
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@ -41,7 +41,7 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,
 {
 	pte_t *pte, oldpte;
 	spinlock_t *ptl;
-	unsigned long pages = 0;
+	unsigned long pages = 0, flags;
 	int target_node = NUMA_NO_NODE;
 
 	/*
@@ -109,6 +109,7 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,
 					continue;
 			}
 
+			flags = hard_local_irq_save();
 			oldpte = ptep_modify_prot_start(vma, addr, pte);
 			ptent = pte_modify(oldpte, newprot);
 			if (preserve_write)
@@ -121,6 +122,7 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,
 				ptent = pte_mkwrite(ptent);
 			}
 			ptep_modify_prot_commit(vma, addr, pte, oldpte, ptent);
+			hard_local_irq_restore(flags);
 			pages++;
 		} else if (IS_ENABLED(CONFIG_MIGRATION)) {
 			swp_entry_t entry = pte_to_swp_entry(oldpte);
-- 
2.16.4

