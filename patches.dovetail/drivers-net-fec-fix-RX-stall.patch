From a1e5807d5251ca2da6549d57737dc31119cf467f Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Tue, 10 Feb 2015 15:08:45 +0100
Subject: [PATCH] drivers/net/fec: fix RX stall

The FEC sees unmasking RXF events in the EIMR while RDAR is cleared as
an error, and stops issuing RXF interrupts when it detects such
situation. Since the receive path is fully interrupt-driven, this
usually leads to a complete stall.

The combination of high network load on the receiver side, and delays
on the current CPU (kernel preemption, IRQ activity) may cause the RX
ring to fill up again soon after we pulled some/all of the pending
frames, but _before_ RXF is unmasked in the EIMR, leading to the
obnoxious RX stall.

To prevent this, we pull exactly one frame from the RX ring if RDAR is
zero, _after_ the EIMR was updated. RDAR gets written to as a
consequence of such action, which is enough to re-enable the RXF
event.

Signed-off-by: Philippe Gerum <rpm@xenomai.org>
---
 drivers/net/ethernet/freescale/fec_main.c | 54 +++++++++++++++++++++++++++----
 1 file changed, 48 insertions(+), 6 deletions(-)

diff --git a/drivers/net/ethernet/freescale/fec_main.c b/drivers/net/ethernet/freescale/fec_main.c
index 9b7774f90ba7..fcf0924fd730 100644
--- a/drivers/net/ethernet/freescale/fec_main.c
+++ b/drivers/net/ethernet/freescale/fec_main.c
@@ -1619,11 +1619,54 @@ fec_enet_interrupt(int irq, void *dev_id)
 	return ret;
 }
 
+static int unmask_events(struct net_device *ndev, unsigned int events)
+{
+	struct fec_enet_private *fep = netdev_priv(ndev);
+	struct fec_enet_priv_rx_q *rxq;
+	int n, queue_id;
+
+	writel(events, fep->hwp + FEC_IMASK);
+	dmb();
+
+	if ((events & FEC_ENET_RXF) == 0)
+		return 0;
+
+	/*
+	 * The FEC sees the unmasking of RXF events in the EIMR while
+	 * RDAR is cleared as an error, and stops issuing RXF
+	 * interrupts as a consequence of this. Since the receive path
+	 * is fully interrupt-driven, this leads to a stall.
+	 *
+	 * Unfortunately, the combination of high network load on the
+	 * receiver side, and delays on the current CPU (kernel
+	 * preemption, IRQ activity) may cause the RX ring to fill up
+	 * again soon after we pulled some/all of the pending frames,
+	 * but _before_ RXF is unmasked in the EIMR, leading to the
+	 * obnoxious RX stall.
+	 *
+	 * To prevent this, we pull exactly one frame from the RX ring
+	 * if RDAR is zero, _after_ the EIMR was updated. RDAR gets
+	 * written to as a consequence of such update, which is enough
+	 * to re-enable the RXF event.
+	 *
+	 * NOTE: a request to unmask RXF implies that we did not
+	 * consume the entire NAPI budget for the current round. This
+	 * means that we may pull at least one more frame without
+	 * exceeding the allowed weight (NAPI_POLL_WEIGHT).
+	 */
+	for (n = 0; n < FEC_ENET_MAX_RX_QS; n++) {
+		queue_id = FEC_ENET_GET_QUQUE(n);
+		rxq = fep->rx_queue[queue_id];
+		if (rxq && readl(rxq->bd.reg_desc_active) == 0)
+			return fec_enet_rx_queue(ndev, 1, queue_id);
+	}
+
+	return 0;
+}
+
 static int fec_enet_rx_napi(struct napi_struct *napi, int budget)
 {
-	unsigned int imask = FEC_ENET_TXF | FEC_NAPI_IMASK;
 	struct net_device *ndev = napi->dev;
-	struct fec_enet_private *fep = netdev_priv(ndev);
 	int pkts;
 
 	pkts = fec_enet_rx(ndev, budget);
@@ -1632,10 +1675,9 @@ static int fec_enet_rx_napi(struct napi_struct *napi, int budget)
 
 	if (pkts < budget) {
 		napi_complete_done(napi, pkts);
-		imask |= FEC_ENET_RXF;
-	}
-
-	writel(imask, fep->hwp + FEC_IMASK);
+		pkts += unmask_events(ndev, FEC_DEFAULT_IMASK);
+	} else
+		unmask_events(ndev, FEC_RX_DISABLED_IMASK);
 
 	return pkts;
 }
-- 
2.16.4

