From 5ab25f41c206df65ffb500a397217fd23e818077 Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Tue, 26 Jun 2018 12:04:25 +0200
Subject: [PATCH] mm: dovetail: allow force commit of pages in mappings

Signed-off-by: Philippe Gerum <rpm@xenomai.org>
---
 include/linux/mm.h             | 11 ++++++++
 include/linux/sched/coredump.h |  1 +
 mm/memory.c                    | 60 ++++++++++++++++++++++++++++++++++++++++++
 mm/mprotect.c                  |  7 +++++
 4 files changed, 79 insertions(+)

diff --git a/include/linux/mm.h b/include/linux/mm.h
index 80a9162b406c..9551fb86860c 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -2877,5 +2877,16 @@ unsigned long wp_shared_mapping_range(struct address_space *mapping,
 				      pgoff_t first_index, pgoff_t nr);
 #endif
 
+#ifdef CONFIG_DOVETAIL
+int commit_vma(struct mm_struct *mm, struct vm_area_struct *vma);
+int force_commit_memory(void);
+#else
+static inline
+int commit_vma(struct mm_struct *mm, struct vm_area_struct *vma)
+{
+	return 0;
+}
+#endif
+
 #endif /* __KERNEL__ */
 #endif /* _LINUX_MM_H */
diff --git a/include/linux/sched/coredump.h b/include/linux/sched/coredump.h
index ecdc6542070f..cefa20991d06 100644
--- a/include/linux/sched/coredump.h
+++ b/include/linux/sched/coredump.h
@@ -73,6 +73,7 @@ static inline int get_dumpable(struct mm_struct *mm)
 #define MMF_OOM_VICTIM		25	/* mm is the oom victim */
 #define MMF_OOM_REAP_QUEUED	26	/* mm was queued for oom_reaper */
 #define MMF_DISABLE_THP_MASK	(1 << MMF_DISABLE_THP)
+#define MMF_VM_PINNED		31	/* disable ondemand memory */
 
 #define MMF_INIT_MASK		(MMF_DUMPABLE_MASK | MMF_DUMP_FILTER_MASK |\
 				 MMF_DISABLE_THP_MASK)
diff --git a/mm/memory.c b/mm/memory.c
index 45442d9a4f52..ff03045f7313 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -4774,6 +4774,66 @@ long copy_huge_page_from_user(struct page *dst_page,
 }
 #endif /* CONFIG_TRANSPARENT_HUGEPAGE || CONFIG_HUGETLBFS */
 
+#ifdef CONFIG_DOVETAIL
+
+int commit_vma(struct mm_struct *mm, struct vm_area_struct *vma)
+{
+	unsigned int gup_flags;
+	int ret, npages;
+
+	if (vma->vm_flags & (VM_IO | VM_PFNMAP))
+		return 0;
+
+	if (!((vma->vm_flags & VM_DONTEXPAND) ||
+	    is_vm_hugetlb_page(vma) || vma == get_gate_vma(mm))) {
+		ret = populate_vma_page_range(vma, vma->vm_start, vma->vm_end,
+					      NULL);
+		return ret < 0 ? ret : 0;
+	}
+
+	gup_flags = (vma->vm_flags & (VM_WRITE | VM_SHARED)) == VM_WRITE
+		? FOLL_WRITE : 0;
+	npages = DIV_ROUND_UP(vma->vm_end, PAGE_SIZE) - vma->vm_start/PAGE_SIZE;
+	ret = get_user_pages(vma->vm_start, npages, gup_flags, NULL, NULL);
+	if (ret < 0)
+		return ret;
+
+	return ret == npages ? 0 : -EFAULT;
+}
+
+int force_commit_memory(void)
+{
+	struct task_struct *tsk = current;
+	struct vm_area_struct *vma;
+	struct mm_struct *mm;
+	int ret = 0;
+
+	mm = get_task_mm(tsk);
+	if (!mm)
+		return -EPERM;
+
+	down_write(&mm->mmap_sem);
+	if (test_bit(MMF_VM_PINNED, &mm->flags))
+		goto done_mm;
+
+	for (vma = mm->mmap; vma; vma = vma->vm_next) {
+		if (is_cow_mapping(vma->vm_flags) &&
+		    (vma->vm_flags & VM_WRITE)) {
+			ret = commit_vma(mm, vma);
+			if (ret < 0)
+				goto done_mm;
+		}
+	}
+	set_bit(MMF_VM_PINNED, &mm->flags);
+done_mm:
+	up_write(&mm->mmap_sem);
+	mmput(mm);
+
+	return ret;
+}
+
+#endif
+
 #if USE_SPLIT_PTE_PTLOCKS && ALLOC_SPLIT_PTLOCKS
 
 static struct kmem_cache *page_ptl_cachep;
diff --git a/mm/mprotect.c b/mm/mprotect.c
index 78ca356c09c6..b9058a13cb1a 100644
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@ -23,6 +23,7 @@
 #include <linux/swapops.h>
 #include <linux/mmu_notifier.h>
 #include <linux/migrate.h>
+#include <linux/dovetail.h>
 #include <linux/perf_event.h>
 #include <linux/pkeys.h>
 #include <linux/ksm.h>
@@ -307,6 +308,12 @@ unsigned long change_protection(struct vm_area_struct *vma, unsigned long start,
 	else
 		pages = change_protection_range(vma, start, end, newprot, dirty_accountable, prot_numa);
 
+	if (dovetailing() && !prot_numa &&
+	    test_bit(MMF_VM_PINNED, &vma->vm_mm->flags) &&
+	    ((vma->vm_flags | vma->vm_mm->def_flags) & VM_LOCKED) &&
+	    (vma->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)))
+		commit_vma(vma->vm_mm, vma);
+
 	return pages;
 }
 
-- 
2.16.4

