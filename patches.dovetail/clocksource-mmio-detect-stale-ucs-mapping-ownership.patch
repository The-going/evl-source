From 75f28379e7a0cba62f793cb28be658a394eda443 Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Fri, 31 May 2019 21:02:05 +0200
Subject: [PATCH] clocksource: mmio: detect stale ucs mapping ownership

After a fork->exit sequence from a parent process owning an ucs
mapping we could have child_vma->private_data(ucs)->mm == stale_mm,
and that mm_struct could be given to another process later on.

If this happens, the ucs mapping indexed on the stale mm might be
matched when scanning the per-ucs hash table, since the hash key is
based on the mm address. Any random process which is given the
recycled mm_struct could therefore be reusing the stale ucs mapping,
eventually causing invalid accesses as a result of calling
clock_gettime().
---
 drivers/clocksource/mmio.c | 102 +++++++++++++++++++++++++++++----------------
 1 file changed, 66 insertions(+), 36 deletions(-)

diff --git a/drivers/clocksource/mmio.c b/drivers/clocksource/mmio.c
index c80ef569245d..464fbcee2a82 100644
--- a/drivers/clocksource/mmio.c
+++ b/drivers/clocksource/mmio.c
@@ -143,11 +143,42 @@ int __init clocksource_mmio_init(void __iomem *base, const char *name,
 
 static void clksrc_vmopen(struct vm_area_struct *vma)
 {
-	struct clocksource_user_mapping *mapping;
+	struct clocksource_user_mapping *mapping, *clone;
+	struct clocksource_user_mmio *ucs;
+	unsigned long h_key;
 
 	mapping = vma->vm_private_data;
 
-	atomic_inc(&mapping->refs);
+	if (mapping->mm == vma->vm_mm) {
+		atomic_inc(&mapping->refs);
+	} else if (mapping->mm) {
+		/*
+		 * We must be duplicating the original mm upon fork(),
+		 * clone the parent ucs mapping struct then rehash it
+		 * on the child mm key. If we cannot get memory for
+		 * this, mitigate the issue for users by preventing a
+		 * stale parent mm from being matched later on by a
+		 * process which reused its mm_struct (h_key is based
+		 * on this struct address).
+		 */
+		clone = kmalloc(sizeof(*mapping), GFP_KERNEL);
+		if (clone == NULL) {
+			pr_alert("out-of-memory for UCS mapping!\n");
+			atomic_inc(&mapping->refs);
+			mapping->mm = NULL;
+			return;
+		}
+		ucs = mapping->ucs;
+		clone->mm = vma->vm_mm;
+		clone->ucs = ucs;
+		clone->regs = mapping->regs;
+		atomic_set(&clone->refs, 1);
+		vma->vm_private_data = clone;
+		h_key = (unsigned long)vma->vm_mm / sizeof(*vma->vm_mm);
+		spin_lock(&ucs->lock);
+		hash_add(ucs->mappings, &clone->link, h_key);
+		spin_unlock(&ucs->lock);
+	}
 }
 
 static void clksrc_vmclose(struct vm_area_struct *vma)
@@ -185,56 +216,57 @@ static int user_mmio_clksrc_mmap(struct file *file, struct vm_area_struct *vma)
 		return -EINVAL;
 
 	vma->vm_private_data = NULL;
-	vma->vm_ops = &clksrc_vmops;
-	ucs = file->private_data;
 
+	ucs = file->private_data;
 	upper_pfn = ucs->phys_upper >> PAGE_SHIFT;
 	lower_pfn = ucs->phys_lower >> PAGE_SHIFT;
 	bits_upper = fls(ucs->mmio.clksrc.mask) - ucs->bits_lower;
 	if (pages == 2 && (!bits_upper || upper_pfn == lower_pfn))
 		return -EINVAL;
 
-	h_key = (unsigned long)vma->vm_mm / sizeof(*vma->vm_mm);
+	mapping = kmalloc(sizeof(*mapping), GFP_KERNEL);
+	if (!mapping)
+		return -ENOSPC;
 
+	mapping->mm = vma->vm_mm;
+	mapping->ucs = ucs;
+	mapping->regs = (void *)vma->vm_start;
+	atomic_set(&mapping->refs, 1);
+
+	vma->vm_private_data = mapping;
+	vma->vm_ops = &clksrc_vmops;
 	prot = pgprot_noncached(vma->vm_page_prot);
 	addr = vma->vm_start;
 
 	err = remap_pfn_range(vma, addr, lower_pfn, PAGE_SIZE, prot);
 	if (err < 0)
-		return err;
+		goto fail;
 
-	if (pages == 2) {
+	if (pages > 1) {
 		addr += PAGE_SIZE;
 		err = remap_pfn_range(vma, addr, upper_pfn, PAGE_SIZE, prot);
 		if (err < 0)
-			return err;
+			goto fail;
 	}
 
-	mapping = kmalloc(sizeof(*mapping), GFP_KERNEL);
-	if (!mapping)
-		return -ENOSPC;
-
-	mapping->mm = vma->vm_mm;
-	mapping->ucs = ucs;
-	mapping->regs = (void *)vma->vm_start;
+	h_key = (unsigned long)vma->vm_mm / sizeof(*vma->vm_mm);
 
 	spin_lock(&ucs->lock);
 	hash_for_each_possible(ucs->mappings, tmp, link, h_key) {
-		if (tmp->mm != vma->vm_mm)
-			continue;
-		spin_unlock(&ucs->lock);
-
-		kfree(mapping);
-
-		return -EBUSY;
+		if (tmp->mm == vma->vm_mm) {
+			spin_unlock(&ucs->lock);
+			err = -EBUSY;
+			goto fail;
+		}
 	}
 	hash_add(ucs->mappings, &mapping->link, h_key);
 	spin_unlock(&ucs->lock);
 
-	atomic_set(&mapping->refs, 1);
-	vma->vm_private_data = mapping;
-
 	return 0;
+fail:
+	kfree(mapping);
+
+	return err;
 }
 
 static long
@@ -259,31 +291,29 @@ user_mmio_clksrc_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 		return -ENOTTY;
 	}
 
-	ucs = file->private_data;
-
 	h_key = (unsigned long)current->mm / sizeof(*current->mm);
 
-	size = PAGE_SIZE;
+	ucs = file->private_data;
 	upper_pfn = ucs->phys_upper >> PAGE_SHIFT;
 	lower_pfn = ucs->phys_lower >> PAGE_SHIFT;
 	bits_upper = fls(ucs->mmio.clksrc.mask) - ucs->bits_lower;
+	size = PAGE_SIZE;
 	if (bits_upper && upper_pfn != lower_pfn)
 		size += PAGE_SIZE;
 
 	do {
 		spin_lock(&ucs->lock);
 		hash_for_each_possible(ucs->mappings, mapping, link, h_key) {
-			if (mapping->mm != current->mm)
-				continue;
-			spin_unlock(&ucs->lock);
-
-			map_base = mapping->regs;
-			goto found;
+			if (mapping->mm == current->mm) {
+				spin_unlock(&ucs->lock);
+				map_base = mapping->regs;
+				goto found;
+			}
 		}
 		spin_unlock(&ucs->lock);
 
-		map_base =
-			(void *)vm_mmap(file, 0, size, PROT_READ, MAP_SHARED, 0);
+		map_base = (void *)
+			vm_mmap(file, 0, size, PROT_READ, MAP_SHARED, 0);
 	} while (IS_ERR(map_base) && PTR_ERR(map_base) == -EBUSY);
 
 	if (IS_ERR(map_base))
-- 
2.16.4

