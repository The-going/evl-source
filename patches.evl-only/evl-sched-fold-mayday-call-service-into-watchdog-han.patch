From 742c1d3735d910dbfce3a8a0cab9c6d7b91227cb Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Wed, 23 Oct 2019 13:00:57 +0200
Subject: [PATCH] evl/sched: fold mayday call service into watchdog handler

evl_call_mayday() can only apply to a running thread (i.e.  current
and non-blocked EVL-wise), called from an interrupt handler that
preempted it. Since the watchdog handler is the only place where it
would make sense to trigger the mayday signal, fold the latter action
in this code directly.

At this chance, fix a potential race by holding the lock protecting
the ->info flags when raising T_KICKED.
---
 include/evl/thread.h    |  2 --
 kernel/evl/sched/core.c |  8 ++++++--
 kernel/evl/thread.c     | 15 ---------------
 3 files changed, 6 insertions(+), 19 deletions(-)

diff --git a/include/evl/thread.h b/include/evl/thread.h
index 55e8a7f5c9c8..9fa17c8c87b8 100644
--- a/include/evl/thread.h
+++ b/include/evl/thread.h
@@ -278,8 +278,6 @@ void evl_demote_thread(struct evl_thread *thread);
 void evl_signal_thread(struct evl_thread *thread,
 		int sig, int arg);
 
-void evl_call_mayday(struct evl_thread *thread, int reason);
-
 #ifdef CONFIG_SMP
 void evl_migrate_thread(struct evl_thread *thread,
 			struct evl_rq *rq);
diff --git a/kernel/evl/sched/core.c b/kernel/evl/sched/core.c
index b1a3ed25b06f..51a59dd794dd 100644
--- a/kernel/evl/sched/core.c
+++ b/kernel/evl/sched/core.c
@@ -89,9 +89,13 @@ static void watchdog_handler(struct evl_timer *timer) /* hard irqs off */
 		return;
 
 	if (curr->state & T_USER) {
+		xnlock_get(&nklock);
+		curr->info |= T_KICKED;
+		xnlock_put(&nklock);
+		evl_signal_thread(curr, SIGDEBUG, SIGDEBUG_WATCHDOG);
+		dovetail_send_mayday(current);
 		printk(EVL_WARNING "watchdog triggered on CPU #%d -- runaway thread "
 			"'%s' signaled\n", evl_rq_cpu(this_rq), curr->name);
-		evl_call_mayday(curr, SIGDEBUG_WATCHDOG);
 	} else {
 		printk(EVL_WARNING "watchdog triggered on CPU #%d -- runaway thread "
 			"'%s' canceled\n", evl_rq_cpu(this_rq), curr->name);
@@ -99,7 +103,7 @@ static void watchdog_handler(struct evl_timer *timer) /* hard irqs off */
 		 * On behalf on an IRQ handler, evl_cancel_thread()
 		 * would go half way cancelling the preempted
 		 * thread. Therefore we manually raise T_KICKED to
-		 * cause the next blockig call to return early in
+		 * cause the next blocking call to return early in
 		 * T_BREAK condition, and T_CANCELD so that @curr
 		 * exits next time it invokes evl_test_cancel().
 		 */
diff --git a/kernel/evl/thread.c b/kernel/evl/thread.c
index 80ac6f7d7f28..be460a5f1121 100644
--- a/kernel/evl/thread.c
+++ b/kernel/evl/thread.c
@@ -1474,21 +1474,6 @@ static inline int commit_process_memory(void)
 
 #endif /* !CONFIG_MMU */
 
-/* nklock locked, irqs off */
-void evl_call_mayday(struct evl_thread *thread, int reason)
-{
-	struct task_struct *p = thread->altsched.task;
-
-	/* Mayday traps are available to userland threads only. */
-	if (EVL_WARN_ON(CORE, !(thread->state & T_USER)))
-		return;
-
-	thread->info |= T_KICKED;
-	evl_signal_thread(thread, SIGDEBUG, reason);
-	dovetail_send_mayday(p);
-}
-EXPORT_SYMBOL_GPL(evl_call_mayday);
-
 int evl_killall(int mask)
 {
 	int nrkilled = 0, nrthreads, count;
-- 
2.16.4

