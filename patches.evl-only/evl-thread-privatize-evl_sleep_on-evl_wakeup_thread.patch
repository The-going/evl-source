From 6cc1669d99183ee0015165c3bbbd92c23eda3bb5 Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Fri, 11 Oct 2019 17:26:25 +0200
Subject: [PATCH] evl/thread: privatize evl_sleep_on(), evl_wakeup_thread()

These are internal calls which are going to depend on additional
context from their call sites. Only the wait and mutex interfaces
are legit callers.
---
 include/evl/wait.h  | 38 +++++++-------------------------------
 kernel/evl/thread.c |  2 --
 kernel/evl/wait.c   | 33 +++++++++++++++++++++++++++++++++
 3 files changed, 40 insertions(+), 33 deletions(-)

diff --git a/include/evl/wait.h b/include/evl/wait.h
index 1a94d47183fd..8408d559a644 100644
--- a/include/evl/wait.h
+++ b/include/evl/wait.h
@@ -126,6 +126,12 @@ void evl_init_wait(struct evl_wait_queue *wq,
 
 void evl_destroy_wait(struct evl_wait_queue *wq);
 
+void evl_flush_wait_locked(struct evl_wait_queue *wq,
+			int reason);
+
+void evl_flush_wait(struct evl_wait_queue *wq,
+		int reason);
+
 struct evl_thread *evl_wake_up(struct evl_wait_queue *wq,
 			struct evl_thread *waiter);
 
@@ -135,38 +141,8 @@ struct evl_thread *evl_wake_up_head(struct evl_wait_queue *wq)
 	return evl_wake_up(wq, NULL);
 }
 
-/* nklock held, irqs off */
-static __always_inline
-void evl_flush_wait_locked(struct evl_wait_queue *wq, int reason)
-{
-	struct evl_thread *waiter, *tmp;
-
-	requires_ugly_lock();
-
-	trace_evl_flush_wait(wq);
-
-	list_for_each_entry_safe(waiter, tmp, &wq->wchan.wait_list, wait_next)
-		evl_wakeup_thread(waiter, T_PEND, reason);
-}
-
-static __always_inline
-void evl_flush_wait(struct evl_wait_queue *wq, int reason)
-{
-	unsigned long flags;
-
-	no_ugly_lock();
-	xnlock_get_irqsave(&nklock, flags);
-	evl_flush_wait_locked(wq, reason);
-	xnlock_put_irqrestore(&nklock, flags);
-}
-
-static inline
 void evl_abort_wait(struct evl_thread *thread,
-		struct evl_wait_channel *wchan)
-{
-	requires_ugly_lock();
-	list_del(&thread->wait_next);
-}
+		struct evl_wait_channel *wchan);
 
 void evl_reorder_wait(struct evl_thread *thread);
 
diff --git a/kernel/evl/thread.c b/kernel/evl/thread.c
index 0a422d597d78..0d3caeecd0ba 100644
--- a/kernel/evl/thread.c
+++ b/kernel/evl/thread.c
@@ -540,7 +540,6 @@ void evl_sleep_on(ktime_t timeout, enum evl_tmode timeout_mode,
 out:
 	xnlock_put_irqrestore(&nklock, flags);
 }
-EXPORT_SYMBOL_GPL(evl_sleep_on);
 
 bool evl_wakeup_thread(struct evl_thread *thread, int mask, int info)
 {
@@ -586,7 +585,6 @@ bool evl_wakeup_thread(struct evl_thread *thread, int mask, int info)
 
 	return ret;
 }
-EXPORT_SYMBOL_GPL(evl_wakeup_thread);
 
 void evl_hold_thread(struct evl_thread *thread, int mask)
 {
diff --git a/kernel/evl/wait.c b/kernel/evl/wait.c
index 5b16b7946a5a..914e857b08c4 100644
--- a/kernel/evl/wait.c
+++ b/kernel/evl/wait.c
@@ -77,12 +77,45 @@ struct evl_thread *evl_wake_up(struct evl_wait_queue *wq,
 }
 EXPORT_SYMBOL_GPL(evl_wake_up);
 
+/* nklock held, irqs off */
+void evl_flush_wait_locked(struct evl_wait_queue *wq, int reason)
+{
+	struct evl_thread *waiter, *tmp;
+
+	requires_ugly_lock();
+
+	trace_evl_flush_wait(wq);
+
+	list_for_each_entry_safe(waiter, tmp, &wq->wchan.wait_list, wait_next)
+		evl_wakeup_thread(waiter, T_PEND, reason);
+}
+EXPORT_SYMBOL_GPL(evl_flush_wait_locked);
+
+void evl_flush_wait(struct evl_wait_queue *wq, int reason)
+{
+	unsigned long flags;
+
+	no_ugly_lock();
+	evl_spin_lock_irqsave(&wq->lock, flags);
+	evl_flush_wait_locked(wq, reason);
+	evl_spin_unlock_irqrestore(&wq->lock, flags);
+}
+EXPORT_SYMBOL_GPL(evl_flush_wait);
+
 static inline struct evl_wait_queue *
 wchan_to_wait_queue(struct evl_wait_channel *wchan)
 {
 	return container_of(wchan, struct evl_wait_queue, wchan);
 }
 
+/* nklock held, irqs off */
+void evl_abort_wait(struct evl_thread *thread,
+		struct evl_wait_channel *wchan)
+{
+	requires_ugly_lock();
+	list_del(&thread->wait_next);
+}
+
 /* nklock held, irqs off */
 void evl_reorder_wait(struct evl_thread *thread)
 {
-- 
2.16.4

