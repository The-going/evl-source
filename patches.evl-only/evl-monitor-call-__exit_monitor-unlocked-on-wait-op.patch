From 8f15f34feac01dfd1c055ef7ebb3414815914cf8 Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Wed, 9 Oct 2019 11:18:14 +0200
Subject: [PATCH] evl/monitor: call __exit_monitor() unlocked on wait op

---
 include/evl/wait.h   | 16 +++++++++++-----
 kernel/evl/monitor.c | 42 +++++++++++++++++++++++-------------------
 kernel/evl/mutex.c   |  2 ++
 3 files changed, 36 insertions(+), 24 deletions(-)

diff --git a/include/evl/wait.h b/include/evl/wait.h
index df9b42af4364..09fc14f2d037 100644
--- a/include/evl/wait.h
+++ b/include/evl/wait.h
@@ -50,14 +50,10 @@ struct evl_wait_queue {
 	list_for_each_entry_safe(__pos, __tmp,				\
 				&(__wq)->wchan.wait_list, wait_next)
 
-#define evl_wait_timeout(__wq, __timeout, __timeout_mode)		\
+#define evl_wait_schedule()						\
 ({									\
 	int __ret = 0, __info;						\
-	unsigned long __flags;						\
 									\
-	xnlock_get_irqsave(&nklock, __flags);				\
-	evl_add_wait_queue(__wq, __timeout, __timeout_mode);		\
-	xnlock_put_irqrestore(&nklock, __flags);			\
 	evl_schedule();							\
 	__info = evl_current()->info;					\
 	if (__info & T_BREAK)						\
@@ -69,6 +65,16 @@ struct evl_wait_queue {
 	__ret;								\
 })
 
+#define evl_wait_timeout(__wq, __timeout, __timeout_mode)		\
+({									\
+	unsigned long __flags;						\
+									\
+	xnlock_get_irqsave(&nklock, __flags);				\
+	evl_add_wait_queue(__wq, __timeout, __timeout_mode);		\
+	xnlock_put_irqrestore(&nklock, __flags);			\
+	evl_wait_schedule();						\
+})
+
 #define evl_wait(__wq)	evl_wait_timeout(__wq, EVL_INFINITE, EVL_REL)
 
 #define evl_wait_event_timeout(__wq, __timeout, __timeout_mode, __cond)	\
diff --git a/kernel/evl/monitor.c b/kernel/evl/monitor.c
index 0083a0aa0d93..616beda838c7 100644
--- a/kernel/evl/monitor.c
+++ b/kernel/evl/monitor.c
@@ -239,10 +239,11 @@ static int tryenter_monitor(struct evl_monitor *gate)
 	return evl_trylock_mutex(&gate->lock);
 }
 
-/* nklock may be held, irqs off (NONE REQUIRED) */
 static void __exit_monitor(struct evl_monitor *gate,
 			struct evl_thread *curr)
 {
+	no_ugly_lock();
+
 	/*
 	 * If we are about to release the lock which is still pending
 	 * PP (i.e. we never got scheduled out while holding it),
@@ -445,6 +446,9 @@ static int wait_monitor(struct file *filp,
 		goto out;
 	}
 
+	timeout = timespec_to_ktime(req->timeout);
+	tmode = timeout ? EVL_ABS : EVL_REL;
+
 	if (req->gatefd < 0) {
 		ret = wait_monitor_ungated(filp, req, r_value);
 		*r_op_ret = ret;
@@ -483,40 +487,40 @@ static int wait_monitor(struct file *filp,
 		event->gate = gate;
 		event->state->u.event.gate_offset = evl_shared_offset(gate->state);
 	} else if (event->gate != gate) {
+		xnlock_put_irqrestore(&nklock, flags);
 		op_ret = -EBADFD;
-		goto unlock;
+		goto put;
 	}
 
+	evl_add_wait_queue(&event->wait_queue, timeout, tmode);
 	curr->info &= ~T_SIGNAL; /* CAUTION: depends on nklock held ATM */
 
+	xnlock_put_irqrestore(&nklock, flags);
+
 	__exit_monitor(gate, curr);
 
 	/*
-	 * Wait on the event. If a break condition is raised such as
-	 * an inband signal pending, do not attempt to reacquire the
-	 * gate lock just yet as this might block indefinitely (in
-	 * theory) and we want the inband signal to be handled
-	 * asap. So exit to user mode, allowing any pending signal to
-	 * be handled during the transition, then expect userland to
-	 * issue UNWAIT to recover (or exit, whichever comes first).
+	 * Actually wait on the event. If a break condition is raised
+	 * such as an inband signal pending, do not attempt to
+	 * reacquire the gate lock just yet as this might block
+	 * indefinitely (in theory) and we want the inband signal to
+	 * be handled asap. So exit to user mode, allowing any pending
+	 * signal to be handled during the transition, then expect
+	 * userland to issue UNWAIT to recover (or exit, whichever
+	 * comes first).
 	 */
-	timeout = timespec_to_ktime(req->timeout);
-	tmode = timeout ? EVL_ABS : EVL_REL;
-	ret = evl_wait_timeout(&event->wait_queue, timeout, tmode);
+	ret = evl_wait_schedule();
 	if (ret) {
+		xnlock_get_irqsave(&nklock, flags);
 		untrack_event(event);
+		xnlock_put_irqrestore(&nklock, flags);
 		if (ret == -EINTR)
-			goto unlock;
+			goto put;
 		op_ret = ret;
 	}
 
-	if (ret != -EIDRM) {	/* Success or -ETIMEDOUT */
-		xnlock_put_irqrestore(&nklock, flags);
+	if (ret != -EIDRM)	/* Success or -ETIMEDOUT */
 		ret = __enter_monitor(gate, NULL);
-		goto put;
-	}
-unlock:
-	xnlock_put_irqrestore(&nklock, flags);
 put:
 	evl_put_file(efilp);
 out:
diff --git a/kernel/evl/mutex.c b/kernel/evl/mutex.c
index 903a6dd765f5..de7b378becc4 100644
--- a/kernel/evl/mutex.c
+++ b/kernel/evl/mutex.c
@@ -861,6 +861,8 @@ void evl_commit_mutex_ceiling(struct evl_mutex *mutex)
 	unsigned long flags;
 	fundle_t oldh, h;
 
+	no_ugly_lock();
+
 	xnlock_get_irqsave(&nklock, flags);
 
 	/*
-- 
2.16.4

