From a0020b69ecd6458fa61d7122f6a2188bc185bbd3 Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Tue, 29 Jan 2019 19:28:19 +0100
Subject: [PATCH] evl/sched: __evl_schedule() may work on the current rq only

---
 include/evenless/sched.h | 8 +++++---
 kernel/evenless/synch.c  | 2 +-
 2 files changed, 6 insertions(+), 4 deletions(-)

diff --git a/include/evenless/sched.h b/include/evenless/sched.h
index 78fada0ba29..783b4498572 100644
--- a/include/evenless/sched.h
+++ b/include/evenless/sched.h
@@ -270,8 +270,10 @@ bool ___evl_schedule(struct evl_rq *this_rq);
 
 irqreturn_t __evl_schedule_handler(int irq, void *dev_id);
 
-static inline bool __evl_schedule(struct evl_rq *this_rq)
+static inline bool __evl_schedule(void)
 {
+	struct evl_rq *this_rq = this_evl_rq();
+
 	/*
 	 * If we race here reading the scheduler state locklessly
 	 * because of a CPU migration, we must be running over the
@@ -305,7 +307,7 @@ static inline void __evl_disable_preempt(void)
 static inline void __evl_enable_preempt(void)
 {
 	if (--dovetail_current_state()->preempt_count == 0)
-		__evl_schedule(this_evl_rq());
+		__evl_schedule();
 }
 
 #ifdef CONFIG_EVENLESS_DEBUG_LOCKING
@@ -336,7 +338,7 @@ static inline bool evl_schedule(void)
 	if (unlikely(evl_preempt_count() > 0))
 		return false;
 
-	return __evl_schedule(this_evl_rq());
+	return __evl_schedule();
 }
 
 static inline bool evl_in_irq(void)
diff --git a/kernel/evenless/synch.c b/kernel/evenless/synch.c
index 3cdcc0f829f..51e228e901e 100644
--- a/kernel/evenless/synch.c
+++ b/kernel/evenless/synch.c
@@ -106,7 +106,7 @@ int block_thread_timed(ktime_t timeout, enum evl_tmode timeout_mode,
 	 * FIXME: bypass sched_lock test until the situation is fixed
 	 * for evl_enable/disable_preempt().
 	 */
-	__evl_schedule(curr->rq);
+	__evl_schedule();
 
 	return curr->info & (T_RMID|T_TIMEO|T_BREAK);
 }
-- 
2.16.4

