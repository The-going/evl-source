From 72d682d1650b3b1495b09cd4e15af53d9f0b73d5 Mon Sep 17 00:00:00 2001
From: Philippe Gerum <rpm@xenomai.org>
Date: Sat, 26 Jan 2019 12:47:25 +0100
Subject: [PATCH] evl/wait: strip unused bits before overhaul

---
 include/evenless/wait.h | 158 +++++++++---------------------------------------
 1 file changed, 30 insertions(+), 128 deletions(-)

diff --git a/include/evenless/wait.h b/include/evenless/wait.h
index 1fe8e5f8655..328e5800661 100644
--- a/include/evenless/wait.h
+++ b/include/evenless/wait.h
@@ -7,21 +7,25 @@
 #ifndef _EVENLESS_WAIT_H
 #define _EVENLESS_WAIT_H
 
+#include <linux/spinlock.h>
 #include <evenless/synch.h>
 #include <evenless/sched.h>
-#include <evenless/poller.h>
 
 /*
  * FIXME: general rework pending. Maybe merge that with synch.h. as
- * evenless/wait.h.
+ * evenless/wait.h, provided the superlock is gone and synch.c
+ * serializes with a local per-synch lock, which would allow to turn
+ * evl_syn into evl_wait_queue.
  */
 
 struct evl_wait_queue {
 	struct evl_syn wait;
+	hard_spinlock_t lock;
 };
 
 #define EVL_WAIT_INITIALIZER(__name) {	\
 		.wait = EVL_SYN_INITIALIZER((__name).wait, EVL_SYN_PRIO), \
+		.lock = __HARD_SPIN_LOCK_INITIALIZER((__name).lock),	  \
 	}
 
 #define DEFINE_EVL_WAIT(__name)	\
@@ -39,129 +43,20 @@ static inline void evl_destroy_wait(struct evl_wait_queue *wq)
 	evl_destroy_syn(&wq->wait);
 }
 
-static inline int evl_wait(struct evl_wait_queue *wq,
-			   ktime_t timeout, enum evl_tmode timeout_mode)
-{
-	int ret;
-
-	ret = evl_sleep_on_syn(&wq->wait, timeout, timeout_mode);
-	if (ret & T_BREAK)
-		return -EINTR;
-	if (ret & T_TIMEO)
-		return -ETIMEDOUT;
-	if (ret & T_RMID)
-		return -EIDRM;
-	return 0;
-}
-
-static inline
-int evl_wait_timeout(struct evl_wait_queue *wq,
-		     ktime_t timeout, enum evl_tmode timeout_mode)
-{
-	return evl_wait(wq, timeout, timeout_mode);
-}
-
-/*
- * nklock held. Whine loudly if not atomic until we have eliminated
- * the superlock.
- */
-#define evl_wait_event(__wq, __cond)					\
-	({								\
-		int __ret = 0;						\
-		atomic_only();						\
-		while (__ret == 0 && !(__cond))				\
-			__ret = evl_wait(__wq,				\
-					 EVL_INFINITE, EVL_REL); \
-		__ret;							\
-	})
-
-/* nklock held. */
-#define evl_wait_event_timeout(__wq, __cond, __timeout, __mode)		\
-	({								\
-		int __ret = 0;						\
-		atomic_only();						\
-		while (__ret == 0 && !(__cond))				\
-			__ret = evl_wait_timeout(__wq, __timeout, __mode); \
-		__ret;							\
-	})
-
-/* nklock held. */
-static inline
-struct evl_thread *evl_wait_head(struct evl_wait_queue *wq)
-{
-	atomic_only();
-	return evl_syn_wait_head(&wq->wait);
-}
-
-static inline
-bool evl_wait_active(struct evl_wait_queue *wq)
-{
-	return evl_syn_has_waiter(&wq->wait);
-}
+struct evl_wait_flag {
+	struct evl_wait_queue wq;
+	bool signaled;
+};
 
-#define evl_wake_up_nosched(__wq)				\
-	({							\
-		struct evl_thread *__waiter;			\
-		__waiter = evl_wake_up_syn(&(__wq)->wait);	\
-		__waiter != NULL;				\
-	})
-
-#define evl_wake_up(__wq)				\
-	({						\
-		bool __ret = evl_wake_up_nosched(__wq);	\
-		evl_schedule();				\
-		__ret;					\
-	})
-
-#define evl_wake_up_all_nosched(__wq)		\
-	evl_flush_syn(&(__wq)->wait, 0)
-
-#define evl_wake_up_all(__wq)					\
-	({							\
-		bool __ret = evl_wake_up_all_nosched(__wq);	\
-		evl_schedule();					\
-		__ret;						\
-	})
-
-#define evl_flush_wait_nosched(__wq)		\
-	evl_flush_syn(&(__wq)->wait, T_BREAK)
-
-#define evl_flush_wait(__wq)				\
-	({						\
-		__ret = evl_flush_wait_nosched(__wq);	\
-		evl_schedule();				\
-		__ret;					\
-	})
-
-/* Does not reschedule(), complete with evl_schedule(). */
-#define evl_wake_up_targeted(__wq, __waiter)			\
-	evl_wake_up_targeted_syn(&(__wq)->wait, __waiter)
-
-/* nklock held */
-#define evl_for_each_waiter(__pos, __wq)		\
-	evl_for_each_syn_waiter(__pos, &(__wq)->wait)
-
-/* nklock held */
-#define evl_for_each_waiter_safe(__pos, __tmp, __wq)			\
-	evl_for_each_syn_waiter_safe(__pos, __tmp, &(__wq)->wait)
-
-	struct evl_wait_flag {
-		struct evl_wait_queue wq;
-		struct evl_poll_head poll_head;
-		bool signaled;
-	};
-
-#define DEFINE_EVL_WAIT_FLAG(__name)				\
+#define DEFINE_EVL_WAIT_FLAG(__name)					\
 	struct evl_wait_flag __name = {					\
 		.wq = EVL_WAIT_INITIALIZER((__name).wq),		\
-		.poll_head = EVL_POLLHEAD_INITIALIZER((__name).poll_head), \
 		.signaled = false,					\
 	}
 
 static inline void evl_init_flag(struct evl_wait_flag *wf)
 {
 	evl_init_wait(&wf->wq);
-	evl_init_poll_head(&wf->poll_head);
 	wf->signaled = false;
 }
 
@@ -178,14 +73,21 @@ static inline int evl_wait_flag_timeout(struct evl_wait_flag *wf,
 
 	xnlock_get_irqsave(&nklock, flags);
 
-	if (!wf->signaled)
-		ret = evl_wait_event_timeout(&wf->wq, wf->signaled,
-					     timeout, timeout_mode);
-	if (ret == 0) {
-		wf->signaled = false;
-		evl_clear_poll_events(&wf->poll_head, POLLIN|POLLRDNORM);
+	while (!wf->signaled) {
+		ret = evl_sleep_on_syn(&wf->wq.wait, timeout, timeout_mode);
+		if (ret & T_BREAK)
+			ret = -EINTR;
+		if (ret & T_TIMEO)
+			ret = -ETIMEDOUT;
+		if (ret & T_RMID)
+			ret = -EIDRM;
+		if (ret)
+			break;
 	}
 
+	if (ret == 0)
+		wf->signaled = false;
+
 	xnlock_put_irqrestore(&nklock, flags);
 
 	return ret;
@@ -196,26 +98,26 @@ static inline int evl_wait_flag(struct evl_wait_flag *wf)
 	return evl_wait_flag_timeout(wf, EVL_INFINITE, EVL_REL);
 }
 
-static inline
+static inline			/* nklock held. */
 struct evl_thread *evl_wait_flag_head(struct evl_wait_flag *wf)
 {
-	return evl_wait_head(&wf->wq);
+	return evl_syn_wait_head(&wf->wq.wait);
 }
 
 static inline bool evl_raise_flag(struct evl_wait_flag *wf)
 {
+	struct evl_thread *waiter;
 	unsigned long flags;
-	bool ret;
 
 	xnlock_get_irqsave(&nklock, flags);
 
 	wf->signaled = true;
-	evl_signal_poll_events(&wf->poll_head, POLLIN|POLLRDNORM);
-	ret = evl_wake_up(&wf->wq);
+	waiter = evl_wake_up_syn(&wf->wq.wait);
+	evl_schedule();
 
 	xnlock_put_irqrestore(&nklock, flags);
 
-	return ret;
+	return waiter != NULL;
 }
 
 #endif /* _EVENLESS_WAIT_H */
-- 
2.16.4

